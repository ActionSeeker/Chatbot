

def train(self,nr_iter,examples):
	for i in range(nr_iter):
		for features, true_yag in examples:
			guess = self.predict(features)
			if guess != true_tag:
				for f in features:
					self.weights[f][true_tag] += 1
					self.weights[f][guess] -= 1
		random.shuffle(examples)

def update(self,truth,guess,features):
	def upd_feat(c,f,v):
		nr_iters_at_this_weight = self.i - self._timestamps[f][c]
		self._totals[f][c] += nr_iters_at_this_weight * self.weights[f][c]
		self.weights[f][c] += v
		self._timestamps[f][c] = self.i

	self.i += 1
	for f in features:
		upd_feat(truth,f,1.0)
		upd_feat(guess,f,-1.0)


def _get_features(self,i,word,context,prev,prev2):
	def add(name,*args):
		features.add('+'.join((name,) + tuple(args)))

	features = set()
	add('bias')
	add('i suffix',word[-3:0])
	add('i prefl', word[0])
	add('i-1 tag',prev)
	add('i-2 tag',prev2)
	add('i tag+i-2 tag'prev,prev2)
	add('i word',context[i])
	add('i-1 tag+i word',prev,context[i])
	add('i-1 word',context[i-1])
	add('i-1 suffix',context[i-1][-3:])
	add('i-2 word' context[i-2])
	add('i+1 word', context[i+1])
	add('i+1 suffix',context[i+1][-3:])
	add('i+2 word',context[i+2])
	return features

def train(self, sentences, save_loc=None, nr_iter=5, quiet=False):
    '''Train a model from sentences, and save it at save_loc. nr_iter
    controls the number of Perceptron training iterations.'''
    self._make_tagdict(sentences, quiet=quiet)
    self.model.classes = self.classes
    prev, prev2 = START
    for iter_ in range(nr_iter):
        c = 0; n = 0
        for words, tags in sentences:
            context = START + [self._normalize(w) for w in words] + END
            for i, word in enumerate(words):
                guess = self.tagdict.get(word)
                if not guess:
                    feats = self._get_features(i, word, context, prev, prev2)
                    guess = self.model.predict(feats)
                    self.model.update(tags[i], guess, feats)
                # Set the history features from the guesses, not the true tags
                prev2 = prev; prev = guess
                c += guess == tags[i]; n += 1
        random.shuffle(sentences)
        if not quiet:
            print(&quot;Iter %d: %d/%d=%.3f&quot; % (iter_, c, n, _pc(c, n)))
    self.model.average_weights()
    # Pickle as a binary file
    if save_loc is not None:
        cPickle.dump((self.model.weights, self.tagdict, self.classes),
                     open(save_loc, 'wb'), -1)
